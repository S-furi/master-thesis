%!TEX root = ../thesis-main.tex
\chapter{An Introduction to Simulation}\label{ch:introduction}
The scientific method begins with the formulation of a \emph{theory}, a
hypothesis that can, in principle, be falsified or corroborated. This
constitutes the first scientific pillar: the theoretical assumptions and
knowledge used to describe a phenomenon, a property, or a behaviour. The
process of gathering evidence to assess a theory is the role of
\emph{experiments}, namely a series of observations of the real world that
confirm or refute the initial hypothesis. In the modern era, computer systems
underpin a large fraction of scientific discovery, whether by providing raw
computing power (e.g. solving weather-forecasting equations on massively
parallel computers) or by enabling virtual representations of the real
world~\cite{Post2005-kn}. With the widespread adoption of simulation and
simulators, researchers increasingly view simulation as a \emph{third pillar}
of science, complementing theory and experiments. Some argue that simulation
cannot be compared to experimentation, while others claim that the two share
important commonalities~\cite{WinsbergEric2010Sita}.

Within this framework, theory provides models for hypotheses, experiments
validate those models against reality, and simulation can generate new insights
or new hypotheses to be tested experimentally. Simulation is therefore essential in
many scientific workflows, and the literature reports successful applications
across disciplines, from biology to physics and from chemistry to the social
sciences.

\section{Simulation and modeling}
As noted above, simulation allows researchers to investigate systems that are
too complex for analytical solutions, or too dangerous, expensive, or slow to
study in the real world. To build a valid simulation, however, one must
first establish a rigorous mathematical foundation for representing reality.

\subsection{System modeling concepts}

Systems modeling, and general systems theory more broadly, provide the
conceptual basis for understanding complex phenomena. They enable a precise and
general mathematical representation of systems, emphasising both input--output
\emph{causal} relationships and goal-seeking behaviours~\cite{mesarovic1975general}.

According to the framework established by ~\cite{Zeigler:2000}, a simulation
study involves four distinct entities and their relationships, as illustrated
in \Cref{fig:ms_framework}:
%
\includediagram[0.8\linewidth]{figures/diagrams/entities_ms.tex}{The Modeling and Simulation Framework.}{fig:ms_framework}
%
\begin{itemize}
	\item the \emph{source system} is the real or virtual environment under
		study, serving as the source of behavioural data.
	\item the \emph{model} is a set of instructions, rules, equations, or
		constraints that form a logical representation of the system;
	\item the \emph{simulation} is the computational device (e.g. an
		algorithm) that interprets the model's instructions to generate
		state trajectories over time;
	\item the \emph{experimental frame} is a specification of the
		conditions under which the system is observed or experimented
		with.
\end{itemize}
A fundamental concept linking these entities is the \emph{state}. The state of a
system at a given time $t$ is defined as the information required to determine
the system's output and future behaviour, under the assumption that future
inputs are known.

\subsection{The Simulation Framework}
To make these notions precise, we introduce a general, formal description of a
system and its evolution in time. In particular, we adopt the \emph{System
Specification Tuple}~\cite{Zeigler:2000}, which provides a compact definition
of time, inputs, outputs, states, and the functions that govern state
transitions and output generation:
\begin{equation}\label{eq:sys_spec_tup}
	S = \langle T, X, Y, Q, \Omega, \delta, \lambda \rangle
\end{equation}
where:

\begin{itemize}
	\item $T$: \emph{Time Base}, whether $T \in \mathbb{R}$ or $T \in \mathbb{Z}$;
	\item $X$: the set of \emph{Input Values};
	\item $Y$: the set of \emph{Output Values};
	\item $Q$: the set of \emph{States};
	\item $\Omega$: the set of admissible \emph{Input Segments} (functions of time);
	\item $\delta : Q \times \Omega \rightarrow Q $: the \emph{state transition function};
	\item $\lambda : Q \times X \rightarrow Y$: the \emph{output function}.
\end{itemize}

\paragraph{State Trajectories and Behaviour:}\label{par:state_trajectories} The
primary goal of a \emph{simulator} is to compute the evolution over time of the
system specified by \eqref{eq:sys_spec_tup}. Starting from an initial state
$q_0 \in Q$ at time $t_0$ and given an input segment $\omega \in \Omega$, the
simulation applies the transition function $\delta$ to generate a \emph{state
trajectory}, i.e. a sequence or function describing the evolution of $q(t)$ for
all $t \in T$. Similarly, by applying the output function $\lambda$, the
simulation generates the \emph{output trajectory}.

\section{Simulation Formalisms}

Depending on a simulator's purpose and constituent elements, different
formalisms arise primarily from how the time base $T$ is defined and how the
state-transition function $\delta$ is evaluated. In particular, we distinguish
between simulators whose time progression and function evaluation happen
\emph{continuously} (differential-equation models, \Cref{ssec:dess}), in fixed
steps (discrete-time models, \Cref{ssec:dts}), or by jumping between relevant
instants (discrete-event models, \Cref{ssec:devs}). Moreover, depending on the
model's nature, the simulation output may be governed by probabilistic
processes (\Cref{ssec:det_stoch_sim}). Finally, when a model involves many
interacting components and non-trivial environmental coupling, so that
behaviour may emerge from these interactions, an agent-oriented approach
(\Cref{ssec:mabs}) can provide an appropriate modeling and simulation
formalism.

\subsection{Discrete Time Simulators}\label{ssec:dts}

The Discrete Time Model assumes a \emph{stepwise} mode of execution where, at a
particular time instant, the model is in a particular state and it defines how
this state changes. Based on its current state and the current input, the model
can determine which will be its state and output in the next time instant.
\emph{Time} in discrete time models advances in discrete steps of integers
multiple of some basic period such as 1 second, 1 day or 1 year.

A discrete time model determines its next state and output at a given time
$t$ with the following functions:

\begin{subequations}
	 \begin{align}
		q(t + 1) & = \delta(q(t), x(t)) \label{eq:state_transition} \\
		y(t) & = \lambda(q(t), x(t)) \label{eq:output_transition}
	 \end{align}
\end{subequations}
Starting from an initial state $q(0)$, we determine the \emph{state trajectory}
$q(0), q(1), \dots$ by applying the \emph{state transition function}
\eqref{eq:state_transition}; similarly, by applying the \emph{output function}
\eqref{eq:output_transition} to the initial state, we obtain the \emph{output
trajectory}.

\paragraph{Cellular Automata as Discrete Time Models:}

With these simple functions a wide spectrum of potentially interesting and
arbitrary complex models could be created. A notable example of modeling and
thereafter simulating models defined through simple state transition and output
functions are \emph{Cellular Automata} ~\cite{Neumann:66}. A
cellular automaton has a set of \emph{cells} (potentially infinite) spatially
located in a grid-like space, where each one of them could have a finite set of
states determined by a set of state transition functions identical for each
cell. State transition functions could be influenced by the
\emph{neighbourhood} of the cell, which most of the time is defined as the set
of cells located nearest in the geometrical sense.

The basic procedure for simulating a cellular automaton is by means of the
discrete time simulation algorithm: at each time tick, every cell of the
environment is scanned and the state transition function is applied,
effectively changing states for those cells whose state transition function
produced a new state different from its current. When all next states have been
computed, the current configuration of all cells constitute the new global
state, and the global tick can advance.

It is rather obvious that either for infinite environment or for particularly
large and complex cellular automata, this approach is unfeasible. If at each
time step we could, instead, ``predict'' which cells could change in the next
time step, the amount of state computation for each step is dramatically
reduced (e.g. in Conway's Game of Life). We could define which cells will
change in the next time step as the cells whose neighboring cells have not
changed at the current state transition time. This key idea is behind the
Discrete Event Simulation (\Cref{ssec:devs}) algorithm, which focuses on
processing events (a cell state change which will trigger a computation of new
possibile states for its neighbours) rather than single cells.

\subsection{Differential Equation Simulators}\label{ssec:dess}

Unlike Discrete Time Models and Discrete Event Models (discussed later in
\Cref{ssec:devs}) where state changes happen at specific time instants, in
Differential Equations Models the next state is not specified directly but a
\emph{rate of change} of the state variables is used to express the evolution
of the model through time. This means that at any particular time instant $t$,
given a state $z$ and an input value $u$, we only know the rate of change of
the state, defined as:
%
\begin{equation}
	\frac{dz}{dt} = f(z, u)
\end{equation}
%
Typically continuous time systems are expressed by using several state
variables, meaning that a continuous time model is formed by a set of \ac{ODE}.
Therefore we can express the \emph{state equation} representation of \ac{ODE}
as:
%
\begin{equation}
	\frac{d\mathbf{z}(t)}{dt} = \mathbf{f}(\mathbf{z}(t), \mathbf{u}(t))
\end{equation}
%
where $\mathbf{z}(t) \triangleq [z_1(t), z_2(t), \dots, z_n(t)]^T$ is the state
vector, the input vector $\mathbf{u}(t) \triangleq [u_1(t), u_2(t), \dots,
u_n(t)]$ and $\mathbf{f} \triangleq [f_1, f_2, \dots, f_n]$ is the vector of
differential equations.

To obtain the state trajectory, the \ac{ODE} must be solved. Solving an
\ac{ODE} \emph{analytically} is often impossible, especially for non-linear
systems. Therefore, simulations utilize numerical integration methods (e.g.
Euler's method, Runge-Kutta for one-step methods, ...). It is also important to
note that because digital computers operate in discrete steps, simulating a
Differential Equation System effectively reduces it to a form of Discrete Time
System. The numerical solver discretises time into small steps $\Delta t$,
calculating ~\cite{cellier2006continuous}:
%
\begin{equation}
    \mathbf{z}(t + \Delta t) \approx \mathbf{z}(t) + \mathbf{f}(\mathbf{z}(t), \mathbf{u}(t)) \cdot \Delta t
\end{equation}
%
Thus, in the context of computer simulation, DESS is often treated as a
special, computationally intensive case of discrete time simulation
~\cite{law2007simulation} with a very fine temporal granularity.

\subsection{Discrete Event Simulators}\label{ssec:devs}
While Discrete Time models advance in fixed steps, Discrete Event models are
characterised by a continuous time base where state changes occur only at
discrete instants called \emph{events}. Between two consecutive events, the
system's state remains unchanged, allowing the simulator to jump over periods
of inactivity, making \ac{DES} highly efficient for sparse systems.

A Discrete Event System (DEVS) can be specified as:
%
\begin{equation}
	M = \langle X, S, Y, \delta_{\text{int}}, \delta_{\text{ext}}, \lambda, \text{ta} \rangle
\end{equation}
%
Where the key components distinguishing from DTSS and DESS are:
\begin{itemize}
	\item \textbf{Time Advance} $\text{ta}: S \rightarrow \mathbb{R}^+_{0,
		\infty}$: a function returning the time the system remains in a
		particular state if no external events occur, defining the
		lifespan of a state. If $\text{ta}(s) = 0$ the state is so
		short that no other event can intervene (\emph{transitory
		state}), whereas $\text{ta}(s) = \infty$ means that the system
		remains in $s$ indefinitely, unless interrupted by an external
		event;
	\item \textbf{Internal Transition} $\delta_{\text{int}}: S \rightarrow S$: this
		function dictates the new state $s' = \delta_{\text{int}}(s)$ after the time $\text{ta}(s)$ has elapsed (autonomous state
		change);
	\item \textbf{External Transition} $\delta_{\text{ext}}: Q \times X
		\rightarrow S$: given the total state set $Q = \{ (s, e) : s
		\in S, 0 \leq e \leq \text{ta}(s)\}$, this function dictates
		the new state $s' = \delta_{\text{ext}}(s, x, e)$ when an input
		$x$ is received in state $s$ after elapsed time $e$.
\end{itemize}
Through this formal definition we can highlight that time in DEVS is not a
global ticker, but a derived property of the system's state via the time
advance function.

\paragraph{DES Simulation Mechanism (Event Scheduling):} To execute a formal
DEVS model on a digital computer, the most common approach is by the
\emph{Event Scheduling} method ~\cite{BanksDESS10}. The simulator maintains a
strictly ordered data queue known as the \ac{FEL}, which stores pending events
ordered by their execution time.
The execution proceeds as a sequence of system \emph{snapshots}:
%
\begin{enumerate}
	\item The clock is advanced to the time of the imminent event at the head of the \ac{FEL};
	\item The event is removed from the \ac{FEL} and executed (either applying $\delta_{\text{int}}$ or $\delta_{\text{ext}}$);
	\item The execution may generate new events or cancel or update existing ones by updating the contents of the \ac{FEL};
	\item The process repeats until \ac{FEL} is empty or a termination condition occurs.
\end{enumerate}
%
Most application of \ac{DES} deal with dynamic, stochastic systems (e.g.
chemicals systems). In these cases the time advance $\text{ta}(s)$ often
involves drawing a sample from a statistical distribution (e.g. exponential
distribution for arrival times), making the state trajectory a realisation of a
stochastic process.

\subsection{Multi Agent-based Modeling and Simulation}\label{ssec:mabs}

\ac{MABS} (often also referred to as agent-based modeling and simulation) is a
modeling approach in which a system is described as a population of
interacting \emph{agents} situated in an \emph{environment}. Each agent is
characterised by its own state and by behavioural rules that map observations
into actions. The system-level behaviour is not prescribed directly; instead,
it emerges from local interactions among agents and between agents and their
environment~\cite{MacalNorth2010ABMS,Bonabeau2002ABM}.

From a \emph{simulation} perspective, many agent-based models can be executed
using the same core mechanism discussed for \ac{DES}: the simulator maintains a
global notion of time and progresses by processing scheduled \emph{events}
(e.g. message deliveries, agent activations, resource arrivals,
perception--action updates). When an event is processed, one or more agents
update their state and may schedule future events. In this view, \ac{MABS} can
be interpreted as a form of \ac{DES} in which the state-transition logic is
distributed across autonomous entities, and event generation is driven by
interaction and communication patterns rather than by a single central
process~\cite{MacalNorth2010ABMS,Byrd2019ABIDES}.

A practical challenge in \ac{MABS} is that model specifications often mix
structural elements (agents, environment, interaction topology) with explicit
execution semantics (process ordering and scheduling). To improve
reproducibility, several works advocate standardised descriptions of
agent-based models that explicitly include the \emph{process overview and
scheduling} component, making simulation semantics comparable across
implementations~\cite{GRIMM2006115}.

\subsection{Deterministic and Stochastic Simulation}\label{ssec:det_stoch_sim}
If the simulated model does not contain any probabilistic components, we talk
about \emph{deterministic} simulation. In such models the output is determined
once the set of input quantities and relationships in the model have been
specified. Hence, given a set of initial conditions and inputs, the output
trajectory is unique and reproducible. On the other hand, \emph{stochastic
simulation} introduces probabilistic elements: here the evolution is not a
single path but a realisation of a stochastic process. Stochasticity is
essential in systems where "average" behaviour (e.g. modeled by differential
equations) fails to capture reality. This can occur in \emph{low-granularity}
regimes, such as chemical reactions or particular \ac{MABS} scenario with
sparse populations, where fluctuations and rare events drive the system
dynamics.

In the context of Discrete Event Simulation, stochasticity typically manifests
in the Time Advance function $\text{ta}(s)$. The duration of a state is not
fixed but drawn from a probability distribution (commonly Exponential for
memoryless processes), making the event scheduling itself probabilistic (more
on this in \Cref{ssec:mdt}).

\subsection{Summary and Comparison}

This section introduces simulation as a methodological tool and established the
conceptual vocabulary required for studying simulation rigorously by
introducing the relationship between a source system, a model, a simulator and
an experimental frame. Central to this view is the notion of \emph{state},
which provides the minimal information required to determine future behaviour
(given future inputs) and consequently, to define state and output
trajectories.

At the level of execution semantics, the formalisms discussed above can be
understood primarily as different ways of structuring time and evalueating
state changes:
\begin{itemize}
	\item \emph{Discrete-time simulation} (DTSS) advances time in fixed
		time steps and updated the state at every tick;
	\item \emph{Differential-equation simulation} (DESS) describes
		evolution via rate equations in continuous time, ultimately
		reduced to a discretised stepping procedure due to the usage of
		numerical integration;
	\item \emph{Discrete-event simulation} (DEVS/DES) advances time by
		jumping to the next event time, leaving the state unchanged
		between events.
\end{itemize}

Among these alternatives, \ac{DES} provides a particularly convenient
foundation for complex and stochastic systems. First, it avoids unnecessary
computation by skipping periods of inactivity, which is essential when state
changes are sparse. Second, it offers a clear separation between model dynamics
and execution through mechanisms such as event scheduling and the \ac{FEL}.
Finally, stochasticity is naturally expressed in terms of random event times
and random event outcomes: in many applications, arrival processes, service
times, communication delays and other sources of uncertainty map directly to
the scheduling and processing of events.

A further advantage of the discrete-event formalism is its unifying role: by
treating advance as a state-dependent property and by representing updates as
event occurrences, the DEVS framework can accommodate discretised
continuous-time models and fixed-step discrete-time models withing a common
event based semantics~\cite{Zeigler:2000}. This perspective makes DES a neutral
``core'' formalism for simulation on digital computers, while still covering
behaviours typically introduced via DTSS or DESS.

Finally, agent-based modeling and simulation can be interpreted as an
agent-oriented specification layered on top of a DES execution semantics.
Agents encapsulate local state and decision rule, while interaction and
coordination are realised through discrete events (e.g. activations, message
passing and resource updates). In this sense, \ac{MABS} can be viewed as an
enhances \emph{DES} with a structuring principle that is particularly well
suited to modeling high interactive systems.

\section{The Dependency Problem}

\subsection{Manual Dependency Tracking}\label{ssec:mdt}

